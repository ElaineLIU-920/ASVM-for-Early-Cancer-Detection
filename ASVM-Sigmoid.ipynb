{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from pandas import *\n",
    "from scipy import stats\n",
    "\n",
    "xl = pd.ExcelFile('data2.xlsx')\n",
    "xl.sheet_names # we'll take 7th\n",
    "dfs = {sheet: xl.parse(sheet) for sheet in xl.sheet_names}\n",
    "data1 = dfs['7']\n",
    "data2 = dfs['1'].loc[:,['Patient','Age at Diagnosis']].drop([554]).drop_duplicates()\n",
    "# import datas/et1\n",
    "data3 = pd.read_csv('data1.csv')\n",
    "\n",
    "combined_data = data1.set_index('Patient').join(data2.set_index('Patient')).join(data3.set_index('Patient'))\n",
    "\n",
    "combined_data['label'] = (combined_data['Patient Type'] == 'Healthy').astype(int)\n",
    "combined_data = combined_data.drop(['Patient Type'],axis=1)\n",
    "print('The number of samples and features are %d and %d, respectively'%(combined_data.shape[0],combined_data.shape[1]))\n",
    "\n",
    "\n",
    "x = combined_data.iloc[:, 0:44]\n",
    "x[isnan(x)] = 0\n",
    "y=combined_data.iloc[:,44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SFLA_SVM(x_traincv, y_traincv,x_testcv, y_testcv,kernel,C,gamma=False,degree=False,coef0=False):\n",
    "    clf = svm.SVC(C=C, kernel=kernel,gamma=gamma, coef0=coef0, probability=True,random_state=920).fit(x_traincv, y_traincv)\n",
    "    y_score = clf.predict_proba(x_testcv)[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_testcv, y_score, pos_label=1)\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "    \n",
    "    return roc_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SFLA_SVM_CV(x_train, y_train,n,kernel,C,gamma=False,degree=False,coef0=False):\n",
    "    '''\n",
    "    n: number of splits for k-fold\n",
    "    \n",
    "    '''\n",
    "    KF = KFold(n_splits=n,shuffle=True, random_state=920)\n",
    "    f = []\n",
    "    for train_indexcv,test_indexcv in KF.split(x_train):\n",
    "        x_traincv, x_testcv = x_train.iloc[train_indexcv][:], x_train.iloc[test_indexcv][:]\n",
    "        y_traincv, y_testcv = y_train.iloc[train_indexcv][:], y_train.iloc[test_indexcv][:]\n",
    "        fq = SFLA_SVM(x_traincv, y_traincv,x_testcv, y_testcv,kernel,C,gamma=gamma,degree=degree,coef0=coef0) \n",
    "        f.append(fq) \n",
    "    f = mean(f)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SFLA_SIGMOID(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeCoef0,x_train,y_train):\n",
    "    '''\n",
    "    num_parameter: int, number of parameter to optimize\n",
    "    \n",
    "    num_global: int, the maximum number of global iterations\n",
    "    \n",
    "    num_local: int, the maximum number of local iterations\n",
    "    \n",
    "    m : int, the number of memeplexes\n",
    "    \n",
    "    n : int, the number of frogs in each memeplex\n",
    "    \n",
    "    q : int, the number of frogs in submemeplex\n",
    "    \n",
    "    n1:  number of splits for cross validation for inner loop\n",
    "    \n",
    "    rangeC: list, float, range of parameter C,eg.[10**-2, 10**2]\n",
    "    \n",
    "    rangeGamma: list, float, range of parameter Gamma,eg.[10**-6, 1]\n",
    "    \n",
    "    rangeCoef0: list, float, range of parameter Coef0,eg.[0, 1]\n",
    "\n",
    "    x_train: feature\n",
    "\n",
    "    y_train: lable\n",
    "\n",
    "    '''\n",
    "\n",
    "    #--- Step 0--Initialize parameters ---#\n",
    "    sizeC = 2\n",
    "    sizeGamma = 2\n",
    "    sizeCoef0 = 2\n",
    "    max_step =  [(rangeC[1]-rangeC[0])/sizeC,(rangeGamma[1]-rangeGamma[0])/sizeGamma,(rangeCoef0[1]-rangeCoef0[0])/sizeCoef0]# maximum step size\n",
    "    \n",
    "    #--- Step 1--Generate initial population ---#\n",
    "    frogC = 10**random.uniform(log10(rangeC[0]),log10(rangeC[1]),m*n)\n",
    "    frogGamma = 10**random.uniform(log10(rangeGamma[0]),log10(rangeGamma[1]),m*n)\n",
    "    frogCoef0 = random.uniform(rangeCoef0[0],rangeCoef0[1],m*n)\n",
    "    frog = c_[frogC,frogGamma,frogCoef0]\n",
    "\n",
    "    # Compute the performance value for each frog on validation data #\n",
    "    KF = KFold(n_splits=n1,shuffle=True, random_state=920)\n",
    "    f = zeros((m*n,n1))\n",
    "    j = 0\n",
    "    for train_indexcv,test_indexcv in KF.split(x_train):\n",
    "        x_traincv, x_testcv = x_train.iloc[train_indexcv][:], x_train.iloc[test_indexcv][:]\n",
    "        y_traincv, y_testcv = y_train.iloc[train_indexcv][:], y_train.iloc[test_indexcv][:]\n",
    "        for i in range(m*n):\n",
    "            f[i,j] = SFLA_SVM(x_traincv, y_traincv,x_testcv, y_testcv,kernel,frog[i,0],frog[i,1],frog[i,2])\n",
    "        j+=1\n",
    "    f = f.mean(axis=1)\n",
    "    f_parameter = c_[f,frog]\n",
    "\n",
    "    #--- Step 2--Rank frogs ---#\n",
    "    f_parameter = f_parameter[argsort(f_parameter[:,0])[::-1]]\n",
    "\n",
    "\n",
    "    #######--- Global search start---######\n",
    "    i_global = 0\n",
    "    flag = 0\n",
    "    fBest_iteration = f_parameter[0,0]\n",
    "    weights = [2*(n+1-j)/(n*(n+1)) for j in range(1,n+1)] # weights of ranked frogs in each memeplex\n",
    "    while i_global < num_global:\n",
    "        frog_gb = f_parameter[0,0] # mark the global best frog      \n",
    "        #--- Step 3--Partition frogs into memeplexes ---#\n",
    "        memeplexes = zeros((m,n,num_parameter+1)) # [memeplexes, frog in memeplex,[f,C,Gamma,Coef0] ]\n",
    "        for i in range(m):\n",
    "            memeplexes[i] = f_parameter[linspace(i,m*n+i,num=n,endpoint=False,dtype=int)]\n",
    "\n",
    "        #######--- Local search start---######\n",
    "        #--- Step 4--Memetic evolution within each memeplex ---#\n",
    "        im = 0 # the number of memeplexes that have been optimized\n",
    "        while im < m:\n",
    "            i_local = 0 # counts the number of local evolutionary steps in each memeplex\n",
    "            while i_local < num_local:\n",
    "\n",
    "                #--- Construct a submemeplex ---#\n",
    "                rValue = random.random(n)*weights # random value with probability weights\n",
    "                subindex = sort(argsort(rValue)[::-1][0:q]) # index of selected frogs in memeplex \n",
    "                submemeplex = memeplexes[im][subindex] # form submemeplex\n",
    "\n",
    "                #--- Improve the worst frog's position ---#\n",
    "                # Learn from local best Pb #\n",
    "                Pb = submemeplex[0] # mark the best frog in submemeplex\n",
    "                Pw = submemeplex[q-1] # mark the worst frog in memeplex\n",
    "                S = (Pb-Pw)[1:]*(Pb-Pw)[0] \n",
    "                Uq = Pw[1:]+S\n",
    "                # Check feasible space and the performance #\n",
    "                if (rangeC[0] <= Uq[0] <=rangeC[1]) and (rangeGamma[0] <= Uq[1] <=rangeGamma[1])and(rangeCoef0[0] <= Uq[2] <=rangeCoef0[1]): # check feasible space\n",
    "                    fq = SFLA_SVM_CV(x_train, y_train,n1,kernel,Uq[0],Uq[1],Uq[2])\n",
    "                    if fq < Pw[0]: # if no improvement of performance,learn from global best randomly #\n",
    "                        S = random.random(num_parameter)*(frog_gb-Pw)[1:]\n",
    "                        for i in range(num_parameter):\n",
    "                            if S[i] > 0:\n",
    "                                S[i] = min(S[i],max_step[i])\n",
    "                            else:\n",
    "                                S[i] = min(S[i],-max_step[i])\n",
    "                        Uq = Pw[1:]+S\n",
    "                        if (rangeC[0] <= Uq[0] <=rangeC[1]) and (rangeGamma[0] <= Uq[1] <=rangeGamma[1])\\\n",
    "                        and(rangeCoef0[0] <= Uq[2] <=rangeCoef0[1]): # check feasible space\n",
    "                            fq = SFLA_SVM_CV(x_train, y_train,n1,kernel,Uq[0],Uq[1],Uq[2])\n",
    "                            if fq < Pw[0]: # if no improvement of performance, randomly generate a new frog\n",
    "                                Uq = [10**random.uniform(log10(rangeC[0]),log10(rangeC[1])),10**random.uniform(log10(rangeGamma[0]),log10(rangeGamma[1])),\\\n",
    "                                      random.uniform(rangeCoef0[0],rangeCoef0[1])]\n",
    "                                fq = SFLA_SVM_CV(x_train, y_train,n1,kernel,Uq[0],Uq[1],Uq[2])\n",
    "                        else: # if not in the feasible space, randomly generate a new frog\n",
    "                            Uq = [10**random.uniform(log10(rangeC[0]),log10(rangeC[1])), 10**random.uniform(log10(rangeGamma[0]),log10(rangeGamma[1])),\\\n",
    "                                      random.uniform(rangeCoef0[0],rangeCoef0[1])]\n",
    "                            fq = SFLA_SVM_CV(x_train, y_train,n1,kernel,Uq[0],Uq[1],Uq[2])            \n",
    "                else: # if not in the feasible space, learn from global best randomly \n",
    "                    S = random.random(num_parameter)*(frog_gb-Pw)[1:]\n",
    "                    for i in range(num_parameter):\n",
    "                        if S[i] > 0:\n",
    "                            S[i] = min(S[i],max_step[i])\n",
    "                        else:\n",
    "                            S[i] = min(S[i],-max_step[i])\n",
    "                    Uq = Pw[1:]+S\n",
    "                    if (rangeC[0] <= Uq[0] <=rangeC[1]) and (rangeGamma[0] <= Uq[1] <=rangeGamma[1])\\\n",
    "                    and(rangeCoef0[0] <= Uq[2] <=rangeCoef0[1]): # check feasible space\n",
    "                        fq = SFLA_SVM_CV(x_train, y_train,n1,kernel,Uq[0],Uq[1],Uq[2])\n",
    "                        if fq < Pw[0]: # if no improvement of performance, randomly generate a new frog\n",
    "                            Uq = [10**random.uniform(log10(rangeC[0]),log10(rangeC[1])), 10**random.uniform(log10(rangeGamma[0]),log10(rangeGamma[1])),\\\n",
    "                                  random.uniform(rangeCoef0[0],rangeCoef0[1])]\n",
    "                            fq = SFLA_SVM_CV(x_train, y_train,n1,kernel,Uq[0],Uq[1],Uq[2])\n",
    "                    else: # if not in the feasible space, randomly generate a new frog\n",
    "                        Uq = [10**random.uniform(log10(rangeC[0]),log10(rangeC[1])), 10**random.uniform(log10(rangeGamma[0]),log10(rangeGamma[1])),\\\n",
    "                              random.uniform(rangeCoef0[0],rangeCoef0[1])]\n",
    "                        fq = SFLA_SVM_CV(x_train, y_train,n1,kernel,Uq[0],Uq[1],Uq[2])\n",
    "\n",
    "                #--- Upgrade the memeplex ---# \n",
    "                memeplexes[im][subindex[q-1]] = r_[fq,Uq]\n",
    "                memeplexes[im] =  memeplexes[im][argsort( memeplexes[im][:,0])[::-1]]            \n",
    "\n",
    "                i_local += 1\n",
    "\n",
    "            im += 1\n",
    "        #######--- Local search end---######    \n",
    "\n",
    "        #--- Step 5--Shuffle memeplexes ---#\n",
    "        f_parameter =  memeplexes.reshape(m*n,num_parameter+1)\n",
    "        f_parameter = f_parameter[argsort(f_parameter[:,0])[::-1]]\n",
    "\n",
    "\n",
    "        i_global += 1\n",
    "\n",
    "        #--- Step 6--Check convergence ---#\n",
    "        if f_parameter[0,0] > 0.99:\n",
    "            print('The program was terminated because it reached the optimization goal with f = %.3f' %f_parameter[0,0])\n",
    "            break\n",
    "        if   abs(frog_gb - f_parameter[0,0])<10**-4:\n",
    "            flag +=1\n",
    "        if flag > 30:\n",
    "            break\n",
    "        fBest_iteration = r_[fBest_iteration,f_parameter[0,0]] \n",
    "\n",
    "    #######--- Global search end---######\n",
    "        \n",
    "    return (f_parameter[0],fBest_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Ensemble ---#\n",
    "def OptimizeSVM_SFLA_CV(x,y,n_splits,num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma = False,rangeDegree = False,rangeCoef0 = False):\n",
    "\n",
    "##---Classification with n-fold cross-validation---##\n",
    "#--- x is feature, y is lable, n is number of fold\n",
    "    #---  define K-fold cross validation ---#\n",
    "    KF = KFold(n_splits,shuffle=True, random_state=920)\n",
    "    y_score = []\n",
    "    y_test = []\n",
    "    for train_index,test_index in KF.split(x):\n",
    "        #---  Seperate traing set and test set ---#\n",
    "        x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "        y_train = y.iloc[train_index][:]\n",
    "        \n",
    "        #---  Fill NaN age ---#\n",
    "        x_train[isnan(x_train)] = 0\n",
    "        x_test[isnan(x_test)] = 0    \n",
    "        \n",
    "        ##---  optimize SVM with SFLA---##\n",
    "        x_train = pd.DataFrame(x_train) \n",
    "        y_train = pd.Series(y_train)\n",
    "        if kernel == 'poly':\n",
    "            f_parameter,fBest_iteration = SFLA_POLY(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeDegree,rangeCoef0,x_train,y_train)\n",
    "            # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "            ##---  creat and train the model ---##\n",
    "            clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],degree=f_parameter[3],coef0=f_parameter[4],probability=True,random_state=920)\n",
    "            \n",
    "        \n",
    "        if kernel == 'rbf':\n",
    "            f_parameter,fBest_iteration = SFLA_RBF(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,x_train,y_train)\n",
    "            # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        \n",
    "            ##---  creat and train the model ---##\n",
    "            clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],probability=True,random_state=920)\n",
    "        \n",
    "        if kernel == 'linear':\n",
    "            f_parameter,fBest_iteration = SFLA_LINEAR(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,x_train,y_train)\n",
    "            # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        \n",
    "            ##---  creat and train the model ---##\n",
    "            clf = svm.SVC(kernel=kernel,C=f_parameter[1],probability=True,random_state=920)\n",
    "        \n",
    "        if kernel == 'sigmoid':\n",
    "            f_parameter,fBest_iteration = SFLA_SIGMOID(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeCoef0,x_train,y_train)\n",
    "            # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        \n",
    "            ##---  creat and train the model ---##\n",
    "            clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],coef0=f_parameter[3],probability=True,random_state=920)\n",
    "        \n",
    "        print(f_parameter)\n",
    "        clf.fit(x_train, y_train)\n",
    "        # Plot ROC and calculate AUC\n",
    "        y_score.extend([x[1] for x in clf.predict_proba(x_test).tolist()])\n",
    "        y_test.extend(y[test_index].tolist())\n",
    "        fpr, tpr, threshold = roc_curve(y[test_index], clf.predict_proba(x_test)[:, 1], pos_label=1)\n",
    "        roc_auc = auc(fpr,tpr)\n",
    "        print('AUC:',roc_auc)\n",
    "\n",
    "    # Plot ROC and calculate AUC\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score, pos_label=1)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "#     plt.plot(fpr, tpr, lw=2, label='SVM (AUC = %0.4f)' % roc_auc, linestyle='--')\n",
    "    y_pred = []\n",
    "    for i in range(len(y_score)):\n",
    "        y_pred.append(round(y_score[i]))\n",
    "    print(cm(y_test,y_pred))\n",
    "    a = accuracy_score(y_test,y_pred)\n",
    "    p = precision_score(y_test,y_pred)\n",
    "    r = recall_score(y_test,y_pred)\n",
    "    f1score = f1_score(y_test,y_pred)\n",
    "    print('Accuracy is %0.2f\\nPrecision is %0.2f\\nRecall is %0.2f\\nF1 is %0.2f\\nAUC is %0.4f\\n'% (a, p, r, f1score, roc_auc))      \n",
    "    return clf, a, p, r, f1score,roc_auc, y_pred,y_score,fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "n_splits = 10 # number of splits for outer loop\n",
    "num_parameter = 3# number of parameter to optimize\n",
    "num_global = 30# the maximum number of global iterations\n",
    "num_local = 20# the maximum number of local iterations\n",
    "m =4 # the number of memeplexes\n",
    "n = 8 # the number of frogs in each memeplex\n",
    "q = 5 # the number of frogs in submemeplex\n",
    "n1 = 10 # number of splits for inner loop\n",
    "kernel = 'sigmoid'\n",
    "rangeC = [10**-12, 10**12] # list, float, range of parameter C,eg.[10**-2, 10**2]\n",
    "rangeGamma = [10**-6, 1] # list, float, range of parameter Gamma,eg.[10**-6, 1]\n",
    "rangeCoef0 = [0, 1] # list, float, range of parameter Coef0,eg.[0, 1]\n",
    "clf, a, p, r, f1score,roc_auc, y_pred,y_score,fpr, tpr = OptimizeSVM_SFLA_CV(x,y,n_splits,num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeCoef0=rangeCoef0)\n",
    "end = time.process_time()\n",
    "print('OptimizeSVM_SFLA_CV algorithm takes '+str(end - start)+'seconds.\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "fname = 'ASVM_result_Sigmoid.csv'\n",
    "\n",
    "# header\n",
    "tmp = [['Id', 'Prediction','Probability']]\n",
    "    \n",
    "# add ID numbers for each Y\n",
    "for (i,y) in enumerate(y_pred):\n",
    "    tmp2 = [(i+1), y_pred,y_score]\n",
    "    tmp.append(tmp2)\n",
    "\n",
    "# write CSV file\n",
    "with open(fname, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
