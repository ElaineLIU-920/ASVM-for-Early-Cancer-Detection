{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from pandas import *\n",
    "from scipy import stats\n",
    "\n",
    "xl = pd.ExcelFile('data2.xlsx')\n",
    "xl.sheet_names # we'll take 7th\n",
    "dfs = {sheet: xl.parse(sheet) for sheet in xl.sheet_names}\n",
    "data1 = dfs['7']\n",
    "data2 = dfs['1'].loc[:,['Patient','Age at Diagnosis']].drop([554]).drop_duplicates()\n",
    "# import datas/et1\n",
    "data3 = pd.read_csv('data1.csv')\n",
    "\n",
    "combined_data = data1.set_index('Patient').join(data2.set_index('Patient')).join(data3.set_index('Patient'))\n",
    "\n",
    "combined_data['label'] = (combined_data['Patient Type'] == 'Healthy').astype(int)\n",
    "combined_data = combined_data.drop(['Patient Type'],axis=1)\n",
    "print('The number of samples and features are %d and %d, respectively'%(combined_data.shape[0],combined_data.shape[1]))\n",
    "\n",
    "\n",
    "x = combined_data.iloc[:, 0:44]\n",
    "x[isnan(x)] = 0\n",
    "y=combined_data.iloc[:,44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SFLA_ENet(x_traincv, y_traincv,x_testcv, y_testcv,alpha,l1_ratio):\n",
    "    clf = ElasticNet(alpha,l1_ratio).fit(x_traincv, y_traincv)\n",
    "    y_score = clf.predict(x_testcv)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_testcv, y_score, pos_label=1)\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "    \n",
    "    return roc_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SFLA_ENet_CV(x_train, y_train,n,alpha,l1_ratio):\n",
    "    '''\n",
    "    n: number of splits for k-fold\n",
    "    \n",
    "    '''\n",
    "    KF = KFold(n_splits=n,shuffle=True, random_state=920)\n",
    "    f = []\n",
    "    for train_indexcv,test_indexcv in KF.split(x_train):\n",
    "        x_traincv, x_testcv = x_train.iloc[train_indexcv][:], x_train.iloc[test_indexcv][:]\n",
    "        y_traincv, y_testcv = y_train.iloc[train_indexcv][:], y_train.iloc[test_indexcv][:]\n",
    "        fq = SFLA_ENet(x_traincv, y_traincv,x_testcv, y_testcv,alpha,l1_ratio)\n",
    "        f.append(fq) \n",
    "    f = mean(f)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SFLA(num_parameter,num_global,num_local,m,n,q,n1,rangeAlpha,rangeL1_ratio,x_train,y_train):\n",
    "    '''\n",
    "    num_parameter: int, number of parameter to optimize\n",
    "    \n",
    "    num_global: int, the maximum number of global iterations\n",
    "    \n",
    "    num_local: int, the maximum number of local iterations\n",
    "    \n",
    "    m : int, the number of memeplexes\n",
    "    \n",
    "    n : int, the number of frogs in each memeplex\n",
    "    \n",
    "    q : int, the number of frogs in submemeplex\n",
    "    \n",
    "    n1:  number of splits for cross validation for inner loop\n",
    "    \n",
    "    rangeAlpha: list, float, range of parameter Alpha,eg.[10**-2, 10]\n",
    "    \n",
    "    rangeL1_ratio: list, float, range of parameter L1_ratio,eg.[0, 1]\n",
    "\n",
    "    x_train: feature\n",
    "\n",
    "    y_train: lable\n",
    "\n",
    "    '''\n",
    "\n",
    "    #--- Step 0--Initialize parameters ---#\n",
    "    sizeAlpha = 2\n",
    "    sizeL1_ratio = 2\n",
    "    max_step =  [(rangeAlpha[1]-rangeAlpha[0])/sizeAlpha,(rangeL1_ratio[1]-rangeL1_ratio[0])/sizeL1_ratio]# maximum step size\n",
    "    \n",
    "    #--- Step 1--Generate initial population ---#\n",
    "    frogAlpha = random.uniform(rangeAlpha[0],rangeAlpha[1],m*n)\n",
    "    frogL1_ratio = random.uniform(rangeL1_ratio[0],rangeL1_ratio[1],m*n)\n",
    "    frog = c_[frogAlpha,frogL1_ratio]\n",
    "\n",
    "    # Compute the performance value for each frog on validation data #\n",
    "    KF = KFold(n_splits=n1,shuffle=True, random_state=920)\n",
    "    f = zeros((m*n,n1))\n",
    "    j = 0\n",
    "    for train_indexcv,test_indexcv in KF.split(x_train):\n",
    "        x_traincv, x_testcv = x_train.iloc[train_indexcv][:], x_train.iloc[test_indexcv][:]\n",
    "        y_traincv, y_testcv = y_train.iloc[train_indexcv][:], y_train.iloc[test_indexcv][:]\n",
    "        for i in range(m*n):\n",
    "            f[i,j] = SFLA_ENet(x_traincv, y_traincv,x_testcv, y_testcv,frogAlpha[i],frogL1_ratio[i])\n",
    "        j+=1\n",
    "    f = f.mean(axis=1)\n",
    "    f_parameter = c_[f,frog]\n",
    "\n",
    "    #--- Step 2--Rank frogs ---#\n",
    "    f_parameter = f_parameter[argsort(f_parameter[:,0])[::-1]]\n",
    "\n",
    "\n",
    "    #######--- Global search start---######\n",
    "    i_global = 0\n",
    "    flag = 0\n",
    "    fBest_iteration = f_parameter[0,0]\n",
    "    weights = [2*(n+1-j)/(n*(n+1)) for j in range(1,n+1)] # weights of ranked frogs in each memeplex\n",
    "    while i_global < num_global:\n",
    "        frog_gb = f_parameter[0,0] # mark the global best frog      \n",
    "        #--- Step 3--Partition frogs into memeplexes ---#\n",
    "        memeplexes = zeros((m,n,num_parameter+1)) # [memeplexes, frog in memeplex,[f,C,Gamma] ]\n",
    "        for i in range(m):\n",
    "            memeplexes[i] = f_parameter[linspace(i,m*n+i,num=n,endpoint=False,dtype=int)]\n",
    "\n",
    "        #######--- Local search start---######\n",
    "        #--- Step 4--Memetic evolution within each memeplex ---#\n",
    "        im = 0 # the number of memeplexes that have been optimized\n",
    "        while im < m:\n",
    "            i_local = 0 # counts the number of local evolutionary steps in each memeplex\n",
    "            while i_local < num_local:\n",
    "\n",
    "                #--- Construct a submemeplex ---#\n",
    "                rValue = random.random(n)*weights # random value with probability weights\n",
    "                subindex = sort(argsort(rValue)[::-1][0:q]) # index of selected frogs in memeplex \n",
    "                submemeplex = memeplexes[im][subindex] # form submemeplex\n",
    "\n",
    "                #--- Improve the worst frog's position ---#\n",
    "                # Learn from local best Pb #\n",
    "                Pb = submemeplex[0] # mark the best frog in submemeplex\n",
    "                Pw = submemeplex[q-1] # mark the worst frog in memeplex\n",
    "                S = (Pb-Pw)[1:]*(Pb-Pw)[0] \n",
    "                Uq = Pw[1:]+S\n",
    "                # Check feasible space and the performance #\n",
    "                if (rangeAlpha[0] <= Uq[0] <=rangeAlpha[1]) and (rangeL1_ratio[0] <= Uq[1] <=rangeL1_ratio[1]): # check feasible space\n",
    "                    fq = SFLA_ENet_CV(x_train, y_train,n1,Uq[0],Uq[1])\n",
    "                    if fq < Pw[0]: # if no improvement of performance,learn from global best randomly #\n",
    "                        S = random.random(num_parameter)*(frog_gb-Pw)[1:]\n",
    "                        for i in range(num_parameter):\n",
    "                            if S[i] > 0:\n",
    "                                S[i] = min(S[i],max_step[i])\n",
    "                            else:\n",
    "                                S[i] = min(S[i],-max_step[i])\n",
    "                        Uq = Pw[1:]+S\n",
    "                        if (rangeAlpha[0] <= Uq[0] <=rangeAlpha[1]) and (rangeL1_ratio[0] <= Uq[1] <=rangeL1_ratio[1]): # check feasible space\n",
    "                            fq = SFLA_ENet_CV(x_train, y_train,n1,Uq[0],Uq[1])\n",
    "                            if fq < Pw[0]: # if no improvement of performance, randomly generate a new frog\n",
    "                                Uq = [random.uniform(rangeAlpha[0],rangeAlpha[1]),random.uniform(rangeL1_ratio[0],rangeL1_ratio[1])]\n",
    "                                fq = SFLA_ENet_CV(x_train, y_train,n1,Uq[0],Uq[1])\n",
    "                        else: # if not in the feasible space, randomly generate a new frog\n",
    "                            Uq = [random.uniform(rangeAlpha[0],rangeAlpha[1]),random.uniform(rangeL1_ratio[0],rangeL1_ratio[1])]\n",
    "                            fq = SFLA_ENet_CV(x_train, y_train,n1,Uq[0],Uq[1])           \n",
    "                else: # if not in the feasible space, learn from global best randomly \n",
    "                    S = random.random(num_parameter)*(frog_gb-Pw)[1:]\n",
    "                    for i in range(num_parameter):\n",
    "                        if S[i] > 0:\n",
    "                            S[i] = min(S[i],max_step[i])\n",
    "                        else:\n",
    "                            S[i] = min(S[i],-max_step[i])\n",
    "                    Uq = Pw[1:]+S\n",
    "                    if (rangeAlpha[0] <= Uq[0] <=rangeAlpha[1]) and (rangeL1_ratio[0] <= Uq[1] <=rangeL1_ratio[1]): # check feasible space\n",
    "                        fq = SFLA_ENet_CV(x_train, y_train,n1,Uq[0],Uq[1])\n",
    "                        if fq < Pw[0]: # if no improvement of performance, randomly generate a new frog\n",
    "                            Uq = [random.uniform(rangeAlpha[0],rangeAlpha[1]),random.uniform(rangeL1_ratio[0],rangeL1_ratio[1])]\n",
    "                            fq = SFLA_ENet_CV(x_train, y_train,n1,Uq[0],Uq[1])\n",
    "                    else: # if not in the feasible space, randomly generate a new frog\n",
    "                        Uq = [random.uniform(rangeAlpha[0],rangeAlpha[1]),random.uniform(rangeL1_ratio[0],rangeL1_ratio[1])]\n",
    "                        fq = SFLA_ENet_CV(x_train, y_train,n1,Uq[0],Uq[1])\n",
    "\n",
    "                #--- Upgrade the memeplex ---# \n",
    "                memeplexes[im][subindex[q-1]] = r_[fq,Uq]\n",
    "                memeplexes[im] =  memeplexes[im][argsort( memeplexes[im][:,0])[::-1]]            \n",
    "\n",
    "                i_local += 1\n",
    "\n",
    "            im += 1\n",
    "        #######--- Local search end---######    \n",
    "\n",
    "        #--- Step 5--Shuffle memeplexes ---#\n",
    "        f_parameter =  memeplexes.reshape(m*n,num_parameter+1)\n",
    "        f_parameter = f_parameter[argsort(f_parameter[:,0])[::-1]]\n",
    "\n",
    "\n",
    "        i_global += 1\n",
    "\n",
    "        #--- Step 6--Check convergence ---#\n",
    "        if f_parameter[0,0] > 0.9999:\n",
    "            print('The program was terminated because it reached the optimization goal with f = %.3f' %f_parameter[0,0])\n",
    "            break\n",
    "            \n",
    "        fBest_iteration = r_[fBest_iteration,f_parameter[0,0]] \n",
    "\n",
    "    #######--- Global search end---######\n",
    "        \n",
    "    return (f_parameter[0],fBest_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "start = time.process_time()\n",
    "n_repeat = 10 # number of time that nested k-fold cross validation repeat\n",
    "n_outer = 10 # number of splits for outer loop\n",
    "n_inner = 5 # number of splits for inner loop\n",
    "rangeAlpha = [10**-2, 2] # list, float, range of parameter C,eg.[10**-2, 10**2]\n",
    "rangeL1_ratio = [0, 1] # list, float, range of parameter Gamma,eg.[10**-6, 1]\n",
    "\n",
    "num_parameter = 2# number of parameter to optimize\n",
    "num_global = 30# the maximum number of global iterations\n",
    "num_local = 20# the maximum number of local iterations\n",
    "m =4 # the number of memeplexes\n",
    "n = 8 # the number of frogs in each memeplex\n",
    "q = 5 # the number of frogs in submemeplex\n",
    "\n",
    "auc_split = []\n",
    "for i in range(n_repeat):\n",
    "    ##---Classification with nested 10*10-fold cross-validation---##\n",
    "    #--- x is feature, y is lable, n is number of fold\n",
    "    #---  define K-fold cross validation ---#\n",
    "    KF = StratifiedKFold(n_outer,shuffle=True, random_state=920+i)\n",
    "    \n",
    "    for train_index,test_index in KF.split(x,y):\n",
    "        #---  Seperate traing set and test set ---#\n",
    "        x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "        y_train = y.iloc[train_index][:]\n",
    "        #---  normalize feature values to zero mean and unit variance ---#\n",
    "        # this makes comparing weights more meaningful\n",
    "        #   feature value 0 means the average value for that features\n",
    "        #   feature value of +1 means one standard deviation above average\n",
    "        #   feature value of -1 means one standard deviation below average\n",
    "        scaler = preprocessing.StandardScaler()  \n",
    "        x_train = scaler.fit_transform(x_train)  \n",
    "        x_test  = scaler.transform(x_test)\n",
    "        #---Unbalanced class---#\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        # define SMOTE\n",
    "        smo = SMOTE(random_state=42)\n",
    "        x_train, y_train = smo.fit_sample(x_train,y_train)\n",
    "        x_train =  pd.DataFrame(x_train)\n",
    "        x_test = pd.DataFrame(x_test)\n",
    "        y_train = pd.DataFrame(y_train)\n",
    "        #---  Fill NaN age ---#\n",
    "        x_train[isnan(x_train)] = 0\n",
    "        x_test[isnan(x_test)] = 0\n",
    "        ##---  optimize SVM with SFLA---##\n",
    "        f_parameter,fBest_iteration = SFLA(num_parameter,num_global,num_local,m,n,q,n_inner,rangeAlpha,rangeL1_ratio,x_train,y_train)\n",
    "        ##---  creat and train the model ---##\n",
    "        clf = ElasticNet(alpha=f_parameter[1],l1_ratio=f_parameter[2])\n",
    "        clf.fit(x_train, y_train)\n",
    "        \n",
    "        # Calculate AUC\n",
    "        fpr, tpr, threshold = roc_curve(y.iloc[test_index][:].values, clf.predict(x_test), pos_label=1)\n",
    "        auc_split.append(auc(fpr,tpr))\n",
    "        print(auc_split)\n",
    "\n",
    "end = time.process_time()\n",
    "print('AElastic-Net takes '+str(end - start)+'seconds.\\n') \n",
    "\n",
    "print('AUC in each split:',auc_split)\n",
    "AUC = mean(auc_split)\n",
    "print('Mean of AUC: %.4f' % (AUC))\n",
    "\n",
    "# Confidence interval\n",
    "lower = percentile(auc_split, 2.5)\n",
    "upper = percentile(auc_split, 97.5)\n",
    "print('95%% Confidence interval: [%.4f, %.4f]' % (lower, upper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
